<?xml version="1.0" encoding="utf-8"?>
<search>
  
  
  
  <entry>
    <title>paper reading</title>
    <link href="/2025/12/03/Nested%20Learning/"/>
    <url>/2025/12/03/Nested%20Learning/</url>
    
    <content type="html"><![CDATA[<p>三步法读论文</p><p>第一遍：title+abstract+conclusion</p><p>第二遍：粗读整篇文章，注意看图，把有关引用文献圈出来</p><p>第三遍：代入自己视角，要是我做会用什么方法解决问题</p><h1 id="Nested-Learning-The-Illusion-of-Deep-Learning-Architecture"><a href="#Nested-Learning-The-Illusion-of-Deep-Learning-Architecture" class="headerlink" title="Nested Learning: The Illusion of Deep Learning Architecture"></a>Nested Learning: The Illusion of Deep Learning Architecture</h1><h2 id="一-AI梳理"><a href="#一-AI梳理" class="headerlink" title="一.AI梳理"></a>一.AI梳理</h2><p>这份论文 <strong>《Nested Learning: The Illusion of Deep Learning Architecture》</strong>（嵌套学习：深度学习架构的错觉）是由 Google Research 的研究团队（Ali Behrouz 等人）提出的一项极具颠覆性的理论与实践工作。</p><p>这篇论文的核心观点是：<strong>我们目前所谓的“深度学习架构”（如 Transformer 的层堆叠）和“优化算法”（如 Adam、SGD）在本质上是同一回事，都是不同频率下的嵌套优化问题。</strong></p><p>以下是对这篇论文的精读，包括其核心理念、主要创新点、技术方法以及实验结论。</p><hr><h3 id="1-核心理念：嵌套学习-Nested-Learning-NL"><a href="#1-核心理念：嵌套学习-Nested-Learning-NL" class="headerlink" title="1. 核心理念：嵌套学习 (Nested Learning, NL)"></a>1. 核心理念：嵌套学习 (Nested Learning, NL)</h3><p>论文开篇提出了一个哲学性的反思：目前的深度学习模型（尤其是 LLM）在预训练结束后就是<strong>静态</strong>的，类似于患有“顺行性遗忘症”的大脑——只能处理短期上下文，无法形成新的长期记忆 1。</p><p>为了解决这个问题，作者受神经科学中**脑电波（Brain Waves）**的启发（大脑不同区域以不同频率更新，而非统一时钟），提出了 <strong>嵌套学习 (NL)</strong> 范式。</p><h4 id="NL-的核心定义"><a href="#NL-的核心定义" class="headerlink" title="NL 的核心定义"></a>NL 的核心定义</h4><p>在 NL 视角下，机器学习模型不再是简单的层堆叠，而是一个<strong>嵌套的优化系统</strong>。系统中的每一个组件（无论是 Transformer 的 Attention 层，还是优化器 Adam）都可以被视为一个**联想记忆（Associative Memory）<strong>模块，它们在不同的</strong>层级（Level）<strong>和</strong>频率（Frequency）**上运行 2222。</p><ul><li><p><strong>高频层级（High Frequency）：</strong> 例如 In-Context Learning。模型根据当前的 prompt 快速调整状态。</p></li><li><p><strong>低频层级（Low Frequency）：</strong> 例如预训练权重。它们在海量数据上缓慢更新，存储长期知识。</p></li><li></li></ul><p>  <strong>优化器也是记忆：</strong> 论文证明了 Adam、Momentum 等优化器实际上是“压缩过去梯度信息”的联想记忆模块 3333。</p><hr><h3 id="2-主要创新点"><a href="#2-主要创新点" class="headerlink" title="2. 主要创新点"></a>2. 主要创新点</h3><h4 id="2-1-统一视角：架构即优化，优化即架构"><a href="#2-1-统一视角：架构即优化，优化即架构" class="headerlink" title="2.1 统一视角：架构即优化，优化即架构"></a>2.1 统一视角：架构即优化，优化即架构</h4><p>论文打破了“模型架构”与“训练算法”的界限。</p><p>- </p><p>  <strong>反向传播 (Backprop) 是联想记忆：</strong> 训练神经网络的过程，本质上是在训练每一层去“记忆”输入数据与局部误差信号（梯度）之间的映射 4。</p><p>- </p><p>  <strong>Transformer 是非参数解：</strong> 论文指出，Softmax Attention 实际上是某种回归目标函数的<strong>非参数解</strong>（即不需要训练权重，直接利用数据计算结果）；而 RNN 是该问题的<strong>参数化解</strong> 5。</p><h4 id="2-2-连续体记忆系统-Continuum-Memory-System-CMS"><a href="#2-2-连续体记忆系统-Continuum-Memory-System-CMS" class="headerlink" title="2.2 连续体记忆系统 (Continuum Memory System, CMS)"></a>2.2 连续体记忆系统 (Continuum Memory System, CMS)</h4><p>这是论文在架构上的重大突破。传统的模型将记忆简单分为“短期（Context）”和“长期（Weights）”。</p><p>CMS 提出了一种多时间尺度的记忆设计：</p><ul><li><p>它由一系列 MLP 块组成，每个块有不同的<strong>更新频率</strong>。</p></li><li><p>例如：第 1 层每步更新，第 2 层每 16 步更新，第 3 层每 1000 步更新。</p></li><li></li></ul><p>  <strong>优势：</strong> 这种设计允许模型在不同时间跨度上保留信息，形成从瞬时记忆到永久记忆的连续体，有效缓解灾难性遗忘 6666。</p><h4 id="2-3-自指（Self-Referential）与自我修改"><a href="#2-3-自指（Self-Referential）与自我修改" class="headerlink" title="2.3 自指（Self-Referential）与自我修改"></a>2.3 自指（Self-Referential）与自我修改</h4><p>现有的 Transformer 权重在推理时是固定的。作者设计了 <strong>Self-Modifying Titans</strong>，这是一种能够生成自己的学习目标（Values）并据此修改自身参数的模块 7。这让模型在推理阶段也能进行实质性的“学习”。</p><hr><h3 id="3-具体方法与模型：Hope-M3"><a href="#3-具体方法与模型：Hope-M3" class="headerlink" title="3. 具体方法与模型：Hope &amp; M3"></a>3. 具体方法与模型：Hope &amp; M3</h3><p>基于 NL 理论，作者提出了具体的架构和算法：</p><h4 id="3-1-Hope-架构"><a href="#3-1-Hope-架构" class="headerlink" title="3.1 Hope 架构"></a>3.1 Hope 架构</h4><p><strong>Hope</strong> 是论文提出的核心模型，是一个“神经学习模块”（Neural Learning Module）。</p><p>- </p><p>  <strong>组成：</strong> 它结合了 <strong>Self-Modifying Titans</strong>（用于快速适应的高频层）和 <strong>Continuum Memory System (CMS)</strong>（用于长期存储的低频层）8。</p><ul><li><p><strong>工作流：</strong></p><ol><li>输入数据进入高频层，模型根据当前上下文快速调整参数（In-context Learning）。</li><li>信息传递给低频层（CMS），CMS 根据预设的慢速频率更新其参数，固化知识。</li></ol></li><li></li></ul><p>  <strong>初始化策略：</strong> 可以直接利用预训练好的 Transformer（如 Llama-3）的权重来初始化 CMS 的各层，从而赋予现有模型持续学习的能力 9。</p><h4 id="3-2-Delta-Gradient-Descent-DGD"><a href="#3-2-Delta-Gradient-Descent-DGD" class="headerlink" title="3.2 Delta Gradient Descent (DGD)"></a>3.2 Delta Gradient Descent (DGD)</h4><p>作者认为标准的梯度下降（基于点积相似度，Hebbian 规则）在处理高度相关的 Token 时效率低下。</p><ul><li><p><strong>创新：</strong> 提出了 DGD，这是一种基于 <strong>$L_2$ 回归</strong>的更新规则。</p></li><li></li></ul><p>  <strong>特点：</strong> 更新不仅取决于当前输入，还结合了权重的当前状态，包含了一个自适应的衰减项。这使得模型能更聪明地管理记忆容量 10。</p><h4 id="3-3-M3-优化器-Multi-scale-Momentum-Muon"><a href="#3-3-M3-优化器-Multi-scale-Momentum-Muon" class="headerlink" title="3.3 M3 优化器 (Multi-scale Momentum Muon)"></a>3.3 M3 优化器 (Multi-scale Momentum Muon)</h4><p>既然优化器也是记忆，作者将 CMS 的概念应用到了优化器上。</p><ul><li><p><strong>M3：</strong> 结合了 Adam、Muon（一种正交化优化器）和 CMS。</p></li><li></li></ul><p>  <strong>原理：</strong> 它维护多个动量（Momentum）项，分别对应不同的时间尺度。这让优化器既能利用最近的梯度快速收敛，又能保留久远的梯度信息以把握全局损失概貌 11。</p><hr><h3 id="4-实验结论"><a href="#4-实验结论" class="headerlink" title="4. 实验结论"></a>4. 实验结论</h3><p>论文在多个高难度任务上验证了 Hope 架构和 NL 范式的有效性：</p><ol><li><p><strong>持续学习 (Continual Learning)：</strong></p><ul><li><p>在类增量学习任务（Class Incremental Learning）中，基于 Llama-3 改装的 Hope 模型击败了包括 EWC（弹性权重巩固）和 In-Context Learning 在内的所有基线 12。</p></li><li><p>这证明了多频率更新（CMS）确实能有效缓解灾难性遗忘。</p></li></ul></li><li><p><strong>长上下文理解 (Needle-In-A-Haystack)：</strong></p><ul><li><p>在“大海捞针”测试中，Hope 在单针、多针、多查询等设置下均优于 Transformer 和其他 RNN 变体（如 RWKV-7, Mamba&#x2F;Comba, Titans）13。</p></li><li><p>在 BABILong 基准测试（超长文本推理）中，Hope 在 10M（一千万）长度的上下文中仍能保持高性能，而其他模型早已崩溃 14。</p></li></ul></li><li><p><strong>语言建模与推理：</strong></p><ul><li>在 WikiText 和 Common-sense Reasoning 任务上，从头训练的 Hope 模型在相同参数量下 perplexity（困惑度）更低，准确率更高 15。</li></ul></li><li><p><strong>优化器性能：</strong></p><ul><li>M3 优化器在 ImageNet (ViT) 和语言模型训练中，相比 AdamW 和 Muon 取得了更低的训练和测试损失 16。</li></ul></li></ol><hr><h3 id="5-总结与深度解读"><a href="#5-总结与深度解读" class="headerlink" title="5. 总结与深度解读"></a>5. 总结与深度解读</h3><p><strong>《Nested Learning》</strong> 这篇论文不仅是一个新模型的提出，更是一次对深度学习基础理论的重构。</p><ul><li><strong>核心洞察：</strong> “深度”不仅是空间的堆叠（Layer Depth），更是时间的嵌套（Time&#x2F;Frequency Depth）。目前的 Transformer 只有“预训练”和“推理”两个极端频率，而真正的智能需要介于两者之间的连续频谱。</li><li><strong>错觉 (The Illusion)：</strong> 论文标题所谓的“错觉”，是指我们误以为我们设计的静态架构（ResNet, Transformer）就是智能的全部。实际上，这些架构只是被冻结的、特定频率下的优化过程。</li><li><strong>未来方向：</strong> 论文认为解决灾难性遗忘和长上下文的关键，不在于堆叠更多的层，而在于设计更好的<strong>层级间知识传递 (Knowledge Transfer)</strong> 机制，以及让模型具备<strong>自我修改 (Self-Modifying)</strong> 的能力。</li></ul><p><strong>一句话总结：</strong> 这篇论文教我们用“动态的、多频率的优化过程”去重新审视“静态的神经网络架构”，并给出了实现这种动态系统的具体蓝图——Hope。</p><h2 id="二-阅读顺序"><a href="#二-阅读顺序" class="headerlink" title="二.阅读顺序"></a>二.阅读顺序</h2><p>你好！欢迎来到科研的世界。作为一名本科生，面对《Nested Learning: The Illusion of Deep Learning Architecture》这样一篇兼具<strong>哲学高度、数学重构和架构创新</strong>的论文，感到吃力是非常正常的。这篇论文不同于普通的“刷榜”论文，它试图重塑我们对深度学习的理解。</p><p>为了帮助你高效精读，我为你设计了一套**“四步阶梯阅读法”**。这套方法能帮你从宏观到微观，从概念到细节，逐步拆解这篇硬核论文。</p><hr><h3 id="第一步：宏观扫描（The-“Big-Picture”-Pass）"><a href="#第一步：宏观扫描（The-“Big-Picture”-Pass）" class="headerlink" title="第一步：宏观扫描（The “Big Picture” Pass）"></a>第一步：宏观扫描（The “Big Picture” Pass）</h3><p>目标： 不看数学公式，只看图表和文字，弄懂作者到底在“骂”什么（现有问题），又在“吹”什么（核心哲学）。</p><p>耗时： 约 30-45 分钟</p><p>1. </p><p>   读标题与摘要 1111：</p><ul><li>抓住关键词：<code>Nested Learning (NL)</code>、<code>Illusion</code>、<code>Associative Memory</code>、<code>Continual Learning</code>。</li><li>理解核心隐喻：作者认为现在的 LLM 像患有“顺行性遗忘症”的大脑，只能处理短期上下文，无法形成长期记忆 2。</li></ul><p>2. </p><p>   读引言（Section 1）3：</p><ul><li><p>重点看作者对“深度学习层堆叠”的批判。为什么说堆叠层数不能解决所有问题？（如无法改变计算深度、优化次优解等）4。</p></li><li></li></ul><pre><code class="hljs"> **关键图表：** 仔细看 **Figure 1** 5。理解这种类比：大脑不同区域有不同的脑电波频率（Alpha, Beta, Gamma），对应不同的更新速度。这是整个论文架构设计的灵感来源 6。</code></pre><p>3. </p><p>   读结论（Section 10）7：</p><ul><li>看作者最后是如何总结 NL 的。特别是这句话：优化器和架构本质上都是压缩上下文的联想记忆 8。这会给你一个总体的方向感。</li></ul><hr><h3 id="第二步：概念重构（The-“Concept”-Pass）"><a href="#第二步：概念重构（The-“Concept”-Pass）" class="headerlink" title="第二步：概念重构（The “Concept” Pass）"></a>第二步：概念重构（The “Concept” Pass）</h3><p>目标： 理解论文最颠覆性的理论——“优化器即记忆”。这是读懂后面架构的基础，也是最难理解的部分。</p><p>耗时： 约 1-2 小时</p><p>1. </p><p>   攻克第 3.1 节和 4.1 节（Associative Memory）9999：</p><p>   - </p><pre><code class="hljs"> **核心定义：** 即使你不懂复杂的微积分，也要盯着 **Equation (6)** 10和 **Equation (31)** 11 看。</code></pre><ul><li><p><strong>思考题：</strong> 为什么作者说“反向传播（Backpropagation）是一个联想记忆”？</p><p>- </p><p>  <em>提示：</em> 作者把梯度下降更新权重的过程，解释为让权重去“记忆”输入数据和误差信号之间的映射 12。如果能理解这一点，你就跨过了这篇论文最高的门槛。</p></li></ul><p>2. </p><p>   理解第 4.2 节（Momentum as Memory）13：</p><ul><li><p>通常我们认为动量（Momentum）只是为了加速收敛。作者却说它是一个“记忆模块”，用来压缩<strong>过去梯度的历史信息</strong> 14。</p></li><li></li></ul><pre><code class="hljs"> **关键点：** 既然它是记忆，就可以把它的结构变得更复杂（比如用 MLP 代替简单的线性动量），这就是后来 M3 优化器的由来 15。</code></pre><hr><h3 id="第三步：架构解析（The-“Architecture”-Pass）"><a href="#第三步：架构解析（The-“Architecture”-Pass）" class="headerlink" title="第三步：架构解析（The “Architecture” Pass）"></a>第三步：架构解析（The “Architecture” Pass）</h3><p>目标： 弄清楚作者提出的模型（Hope）到底长什么样，和 Transformer 有什么区别。</p><p>耗时： 约 1 小时</p><ol><li><p><strong>对比阅读图表：</strong></p><ul><li><p>把 <strong>Figure 2</strong> 16和 <strong>Figure 5</strong> 17 放在一起看。</p></li><li></li></ul><p>  <strong>Figure 3</strong> 18 非常重要：它展示了传统视角（Deep Learning Viewpoint）和嵌套学习视角（Nested Learning Viewpoint）的区别。注意看那些“频率”（Frequency）的标注。</p></li><li></li></ol><p>   精读第 7 节（Continuum Memory System, CMS）19：</p><ul><li><p>理解什么是 <strong>CMS</strong>：它不是一层层堆叠，而是一串串不同更新频率的 MLP 20。</p></li><li></li></ul><pre><code class="hljs"> **思考：** 这种设计为什么能解决“灾难性遗忘”？（答案：因为高频层忘掉的东西，低频层还存着，而且可以通过反向传播“回流”）21。</code></pre><p>3. </p><p>   精读第 8 节（Hope 架构）22：</p><ul><li><p>搞清楚 Hope 的两个部分：</p><p>1. </p><p>   <strong>Self-Referential Titans：</strong> 负责高频、快速适应上下文 23。</p><p>2. </p><p>   <strong>CMS：</strong> 负责低频、长期存储知识 24。</p></li></ul><hr><h3 id="第四步：批判性验证（The-“Verification”-Pass）"><a href="#第四步：批判性验证（The-“Verification”-Pass）" class="headerlink" title="第四步：批判性验证（The “Verification” Pass）"></a>第四步：批判性验证（The “Verification” Pass）</h3><p>目标： 看实验结果是否支撑了理论，并思考论文的局限性。</p><p>耗时： 约 45 分钟</p><p>1. </p><p>   看实验部分（Section 9）25：</p><ul><li>关注 <strong>Figure 6</strong> 26（持续学习）：Hope 相比 In-Context Learning (ICL) 的优势在哪里？（在不断学习新任务时，Hope 没有忘记旧任务）。</li><li>关注 <strong>Figure 7</strong> 27（大海捞针）：这证明了 Hope 在长上下文理解上的能力。</li><li>关注 <strong>Figure 12</strong> 28（效率）：留意作者也很诚实地展示了 M3 优化器训练时间较慢的问题 29。这是你在写 Reading Report 时可以提到的局限性。</li></ul><hr><h3 id="给本科生的特别建议（Tips-for-Beginners）"><a href="#给本科生的特别建议（Tips-for-Beginners）" class="headerlink" title="给本科生的特别建议（Tips for Beginners）"></a>给本科生的特别建议（Tips for Beginners）</h3><ol><li><strong>不要被公式吓倒：</strong><ul><li>这篇论文里有很多公式（如 Eq 19-20 30303030），看起来很吓人。<strong>初读时可以跳过推导过程，直接看公式下方的文字解释</strong>。只要知道 Input 是什么，Output 是什么，目的是什么即可。</li><li>如果遇到不懂的数学符号（比如 $\otimes$ 或具体的优化术语），<strong>把公式截图发给 AI</strong>，让它用通俗的语言解释给你听。</li></ul></li><li><strong>建立“术语对照表”：</strong><ul><li>这也是这篇论文难读的原因，它重新定义了很多词。建议你在纸上写下：<ul><li><strong>Optimizer</strong> &#x3D; Memory (记忆模块)</li><li><strong>Architecture</strong> &#x3D; Nested Optimization Problems (嵌套优化问题)</li><li><strong>Layers</strong> &#x3D; Different Frequency Blocks (不同频率的块)</li><li><strong>Context</strong> &#x3D; Data Flow (不仅仅是文本，梯度也是上下文)</li></ul></li></ul></li><li><strong>思考“为什么”而非“是什么”：</strong><ul><li>不要死记 Hope 模型的参数。要思考：<em>为什么作者觉得 Transformer 的 Attention 机制本质上是“无限频率”的更新？</em> 31 这种思考能极大地提升你的科研直觉。</li></ul></li><li><strong>动手（可选）：</strong><ul><li>如果你有代码基础，去 GitHub 找找相关的代码（通常会在论文首页或脚注），看看 <code>Self-Modifying</code> 模块在代码里也就是几行 <code>linear</code> 和 <code>update</code> 操作，这会让你祛魅，发现“神奇的理论背后往往是朴素的代码”。</li></ul></li></ol><p>按照这个顺序读，你不仅能读懂这篇论文，还能学到一种通用的高阶论文阅读方法。加油！</p>]]></content>
    
    
    <categories>
      
      <category>study</category>
      
      <category>computer</category>
      
      <category>research</category>
      
    </categories>
    
    
  </entry>
  
  
  
  <entry>
    <title>c language notes</title>
    <link href="/2025/12/03/The%20C%20Language%20Notes/"/>
    <url>/2025/12/03/The%20C%20Language%20Notes/</url>
    
    <content type="html"><![CDATA[<h1 id="The-C-Language-Notes"><a href="#The-C-Language-Notes" class="headerlink" title="The C Language Notes"></a>The C Language Notes</h1><h1 id="Pointer"><a href="#Pointer" class="headerlink" title="Pointer"></a>Pointer</h1><h2 id="A-要声明不同类型的指针的原因？"><a href="#A-要声明不同类型的指针的原因？" class="headerlink" title="A.要声明不同类型的指针的原因？"></a>A.要声明不同类型的指针的原因？</h2><ul><li><strong>声明不同类型的原因：</strong> <strong>对</strong>。不同类型的指针（如 <code>int *</code> 和 <code>char *</code>）存在的根本原因是为了告诉编译器，它所指向的<strong>对象</strong>有多大，这样才能正确地进行指针算术（如 <code>ptr + 1</code>）。</li><li><strong>指针的“值”没有区别：</strong> <strong>对</strong>。在几乎所有现代计算机架构上，所有类型的指针（<code>int *</code>、<code>char *</code>、<code>double *</code>，甚至 <code>void *</code>）在内存中占据的<strong>空间大小都是一样的</strong>（例如 4 字节或 8 字节），并且它们存储的<strong>地址值</strong>本身也是相同的——它们都只是一个内存地址编号。</li></ul><h3 id="1-指针的“值”（Value）是相同的"><a href="#1-指针的“值”（Value）是相同的" class="headerlink" title="1. 指针的“值”（Value）是相同的"></a>1. 指针的“值”（Value）是相同的</h3><p>指针的“值”就是它存储的那个<strong>内存地址</strong>。对于同一个内存位置，无论是 <code>int *</code> 还是 <code>char *</code> 指向它，它们内部存储的<strong>地址编号</strong>都是一样的。</p><p>Pointer Value&#x3D;Memory Address (e.g., 0x1000)</p><h3 id="2-指针的“类型”（Type）是不同的"><a href="#2-指针的“类型”（Type）是不同的" class="headerlink" title="2. 指针的“类型”（Type）是不同的"></a>2. 指针的“类型”（Type）是不同的</h3><p>指针的“类型”（如 <code>int *</code>、<code>char *</code>）是为了编译器服务的，它定义了<strong>如何解释</strong>指针所指向的内存，具体体现在两方面：</p><h4 id="A-内存步长（指针算术）"><a href="#A-内存步长（指针算术）" class="headerlink" title="A. 内存步长（指针算术）"></a>A. 内存步长（指针算术）</h4><p>这是声明不同类型指针的<strong>主要原因</strong>。当您对指针进行递增或递减操作 (<code>ptr++</code> 或 <code>ptr + 1</code>) 时，编译器需要知道要跳过多少字节。</p><table><thead><tr><th>指针类型</th><th>指向对象的大小</th><th><code>ptr + 1</code> 移动的字节数</th></tr></thead><tbody><tr><td><code>char *</code></td><td>1 字节</td><td>+ 1 字节</td></tr><tr><td><code>int *</code></td><td>4 字节 (常见)</td><td>+ 4 字节</td></tr><tr><td><code>double *</code></td><td>8 字节 (常见)</td><td>+ 8 字节</td></tr></tbody></table><p><strong>结论：</strong> 声明 <code>int *</code> 是在告诉编译器：“这个地址指向一个 4 字节的块，所以下次移动时要跳过 4 个字节。”</p><h4 id="B-解引用类型（Dereferencing-Type）"><a href="#B-解引用类型（Dereferencing-Type）" class="headerlink" title="B. 解引用类型（Dereferencing Type）"></a>B. 解引用类型（Dereferencing Type）</h4><p>当您使用解引用运算符 <code>*</code> 时，编译器需要知道从该地址读取多少字节的数据，并将这些字节解释成什么类型的值。</p><table><thead><tr><th>指针类型</th><th><code>*ptr</code> 行为</th><th>结果类型</th></tr></thead><tbody><tr><td><code>char *</code></td><td>读取 1 个字节</td><td>解释为单个 <code>char</code> 值</td></tr><tr><td><code>int *</code></td><td>读取 4 个字节</td><td>解释为单个 <code>int</code> 值</td></tr></tbody></table><h3 id="3-void-通用指针"><a href="#3-void-通用指针" class="headerlink" title="3. void * (通用指针)"></a>3. <code>void *</code> (通用指针)</h3><p><code>void *</code> 进一步印证了您的观点。<code>void *</code> 是一种<strong>通用指针</strong>，它可以存储<strong>任何类型</strong>对象的地址。</p><ul><li><strong><code>void \*</code> 的值：</strong> 依然是一个地址。</li><li><strong><code>void \*</code> 的类型：</strong> 它<strong>没有</strong>关联的类型信息（不知道指向的对象多大）。因此，您不能直接对 <code>void *</code> 进行指针算术 (<code>ptr + 1</code>) 或解引用 (<code>*ptr</code>)，因为它不知道该移动多少步或读取多少字节。</li></ul><p>要使用 <code>void *</code>，您必须将其<strong>强制转换</strong>回具体的类型，比如 <code>(int *)ptr</code>，这样就重新赋予了它内存步长和解引用的规则。</p><h2 id="B-p-i和-p-i有什么区别"><a href="#B-p-i和-p-i有什么区别" class="headerlink" title="B.p&#x3D;&amp;i和*p&#x3D;i有什么区别"></a>B.p&#x3D;&amp;i和*p&#x3D;i有什么区别</h2><p>这是一个关于指针操作的两个基本、但意义<strong>完全不同</strong>的表达式。理解它们之间的区别是掌握C语言指针的关键。</p><p>假设我们已经声明了一个整数变量 <code>i</code> 和一个指向整数的指针变量 <code>p</code>：</p><p>C</p><figure class="highlight abnf"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><code class="hljs abnf">int i <span class="hljs-operator">=</span> <span class="hljs-number">10</span><span class="hljs-comment">;</span><br>int *p<span class="hljs-comment">;</span><br></code></pre></td></tr></table></figure><p>现在我们来看这两个表达式：</p><hr><h2 id="1-表达式：p-i"><a href="#1-表达式：p-i" class="headerlink" title="1. 表达式：p = &amp;i"></a>1. 表达式：<code>p = &amp;i</code></h2><table><thead><tr><th><strong>操作</strong></th><th><strong>赋值 (Assignment)</strong></th></tr></thead><tbody><tr><td><strong><code>&amp;i</code></strong></td><td><strong>取地址运算符 (Address-of Operator)</strong>：获取变量 <code>i</code> 在内存中的地址。</td></tr><tr><td><strong><code>p = ...</code></strong></td><td>将右侧的值（地址）赋给左侧的指针变量 <code>p</code>。</td></tr></tbody></table><h3 id="含义和作用："><a href="#含义和作用：" class="headerlink" title="含义和作用："></a>含义和作用：</h3><ul><li><strong>目的</strong>：让指针 <code>p</code> <strong>指向</strong>变量 <code>i</code>。</li><li><strong>结果</strong>：指针 <code>p</code> 现在存储了变量 <code>i</code> 的内存地址。</li><li><strong>谁变了？</strong>：<strong>指针 <code>p</code> 的值变了</strong>（它现在存储了一个地址）。变量 <code>i</code> 的值（10）没有改变。</li></ul><h3 id="总结："><a href="#总结：" class="headerlink" title="总结："></a>总结：</h3><p><strong><code>p = &amp;i</code> 是建立联系。它使得指针 <code>p</code> 锁定了变量 <code>i</code> 的位置。</strong></p><hr><h2 id="2-表达式：-p-i"><a href="#2-表达式：-p-i" class="headerlink" title="2. 表达式：*p = i"></a>2. 表达式：<code>*p = i</code></h2><p>这个表达式的前提是：<code>p</code> 已经是一个有效的指针，并且<strong>已经指向了某个内存地址</strong>（例如，通过 <code>p = &amp;j</code> 已经指向了另一个变量 <code>j</code>）。</p><table><thead><tr><th><strong>操作</strong></th><th><strong>解引用赋值 (Dereference Assignment)</strong></th></tr></thead><tbody><tr><td><strong><code>\*p</code></strong></td><td><strong>解引用运算符 (Dereference Operator)</strong>：访问指针 <code>p</code> <strong>所指向的内存位置</strong>。</td></tr><tr><td><strong><code>... = i</code></strong></td><td>将变量 <code>i</code> 的值赋给左侧的内存位置（即 <code>*p</code>）。</td></tr></tbody></table><h3 id="含义和作用：-1"><a href="#含义和作用：-1" class="headerlink" title="含义和作用："></a>含义和作用：</h3><ul><li><strong>目的</strong>：将变量 <code>i</code> 的<strong>值</strong>复制到指针 <code>p</code> <strong>当前指向的内存位置</strong>。</li><li><strong>结果</strong>：<code>p</code> 所指向的变量的值被覆盖为 <code>i</code> 的值。</li><li><strong>谁变了？</strong>：<strong>指针 <code>p</code> 所指向的变量的值变了</strong>。指针 <code>p</code> 自己的值（它存储的地址）和变量 <code>i</code> 的值都没有改变。</li></ul><h3 id="示例场景："><a href="#示例场景：" class="headerlink" title="示例场景："></a>示例场景：</h3><p>假设变量 <code>j</code> 的地址被赋给了 <code>p</code> (<code>p = &amp;j</code>)，并且 <code>j</code> 的初始值是 20。</p><table><thead><tr><th><strong>内存示意图</strong></th></tr></thead><tbody><tr><td><strong>执行前:</strong> <code>i=10, j=20</code> 且 <code>p</code> 指向 <code>j</code>。</td></tr><tr><td><strong>执行后 (执行 <code>\*p = i</code>):</strong></td></tr><tr><td><strong>变量 i</strong></td></tr><tr><td><strong>变量 j</strong></td></tr><tr><td><strong>指针 p</strong></td></tr></tbody></table><h3 id="总结：-1"><a href="#总结：-1" class="headerlink" title="总结："></a>总结：</h3><p><strong><code>\*p = i</code> 是修改数据。它使得指针 <code>p</code> 通过其连接，去修改它所指向的变量的数据。</strong></p><hr><h2 id="关键差异总结"><a href="#关键差异总结" class="headerlink" title="关键差异总结"></a>关键差异总结</h2><table><thead><tr><th><strong>表达式</strong></th><th><strong>操作对象</strong></th><th><strong>内存操作</strong></th><th><strong>作用</strong></th></tr></thead><tbody><tr><td><strong><code>p = &amp;i</code></strong></td><td><strong>指针本身 (<code>p</code>)</strong></td><td>赋值一个地址</td><td><strong>建立连接</strong>：让 <code>p</code> 知道 <code>i</code> 在哪里。</td></tr><tr><td><strong><code>\*p = i</code></strong></td><td><strong><code>p</code> 指向的内存位置 (<code>\*p</code>)</strong></td><td>赋值一个值</td><td><strong>修改数据</strong>：把 <code>i</code> 的值写入 <code>p</code> 指向的地方。</td></tr></tbody></table><h2 id="地址调用"><a href="#地址调用" class="headerlink" title="地址调用"></a>地址调用</h2><h2 id="1-内存中的“栈”（Stack）和“压栈”（Push）"><a href="#1-内存中的“栈”（Stack）和“压栈”（Push）" class="headerlink" title="1. 内存中的“栈”（Stack）和“压栈”（Push）"></a>1. 内存中的“栈”（Stack）和“压栈”（Push）</h2><p>“栈”是计算机内存中一个非常重要的区域，用于管理函数的调用和数据的存储。它遵循 <strong>后进先出 (LIFO)</strong> 的原则。</p><h3 id="压栈的含义"><a href="#压栈的含义" class="headerlink" title="压栈的含义"></a>压栈的含义</h3><p>“压栈”就是将数据<strong>放入</strong>栈顶端的过程。</p><p>在函数调用场景中，压栈有以下作用：</p><ul><li><strong>保存返回地址：</strong> 将<strong>函数调用语句下一条语句的内存地址</strong>保存在栈中。这样，当函数执行完毕后，程序就知道要回到哪里继续执行。</li><li><strong>传递参数：</strong> 存储函数调用时传入的参数。</li><li><strong>分配局部变量：</strong> 为函数内部的局部变量预留存储空间。</li></ul><p><strong>简单例子：</strong></p><p>假设主函数 <code>main</code> 在第 50 行调用了函数 <code>funcA</code>。</p><ol><li><strong>压栈 (Push):</strong> 在跳转到 <code>funcA</code> 之前，程序会将地址 <strong>51</strong>（即 <code>main</code> 函数中下一条语句的地址）压入栈中。</li><li><strong>出栈 (Pop):</strong> <code>funcA</code> 执行完毕，程序从栈顶取出地址 <strong>51</strong>。</li><li><strong>返回：</strong> 程序跳转到第 51 行，继续执行 <code>main</code> 函数的后续代码。</li></ol><hr><h2 id="2-传地址调用-Pass-by-Reference-和指针"><a href="#2-传地址调用-Pass-by-Reference-和指针" class="headerlink" title="2. 传地址调用 (Pass by Reference) 和指针"></a>2. 传地址调用 (Pass by Reference) 和指针</h2><p>传地址调用是C语言中实现函数<strong>双向传递</strong>（在函数内部修改外部变量的值）的主要方法。</p><h3 id="传地址调用机制"><a href="#传地址调用机制" class="headerlink" title="传地址调用机制"></a>传地址调用机制</h3><table><thead><tr><th><strong>序号</strong></th><th><strong>步骤</strong></th><th><strong>关键操作</strong></th></tr></thead><tbody><tr><td>1</td><td>实参准备</td><td><strong>实参必须是变量的地址</strong>（使用 <code>&amp;</code> 符号）。</td></tr><tr><td>2</td><td>形参准备</td><td><strong>形参必须定义为指针变量</strong>（使用 <code>*</code> 符号）。</td></tr><tr><td>3</td><td>调用过程</td><td>函数调用时，实参（地址）传递给形参指针。然后，通过形参指针就可以<strong>影响实参所指向的值</strong>。</td></tr></tbody></table><h3 id="传地址调用的例子"><a href="#传地址调用的例子" class="headerlink" title="传地址调用的例子"></a>传地址调用的例子</h3><p>假设我们要编写一个函数来交换两个整数变量的值。</p><p>C</p><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><code class="hljs c"><span class="hljs-type">void</span> <span class="hljs-title function_">swap</span><span class="hljs-params">(<span class="hljs-type">int</span> *a, <span class="hljs-type">int</span> *b)</span> &#123; <span class="hljs-comment">// 步骤 2: 形参是指针</span><br>    <span class="hljs-type">int</span> temp = *a;           <span class="hljs-comment">// 取出 a 指向的值</span><br>    *a = *b;                 <span class="hljs-comment">// 将 b 指向的值赋给 a 指向的地址</span><br>    *b = temp;               <span class="hljs-comment">// 将 temp 赋给 b 指向的地址</span><br>&#125;<br><br><span class="hljs-type">int</span> <span class="hljs-title function_">main</span><span class="hljs-params">()</span> &#123;<br>    <span class="hljs-type">int</span> x = <span class="hljs-number">10</span>;<br>    <span class="hljs-type">int</span> y = <span class="hljs-number">20</span>;<br><br>    swap(&amp;x, &amp;y); <span class="hljs-comment">// 步骤 1: 实参传递的是 x 和 y 的地址 (&amp;x, &amp;y)</span><br>    <span class="hljs-comment">// 此时 x 变为 20, y 变为 10</span><br>    <span class="hljs-keyword">return</span> <span class="hljs-number">0</span>;<br>&#125;<br></code></pre></td></tr></table></figure><hr><h2 id="3-结合第-3-题的指针和-scanf"><a href="#3-结合第-3-题的指针和-scanf" class="headerlink" title="3. 结合第 3 题的指针和 scanf"></a>3. 结合第 3 题的指针和 <code>scanf</code></h2><p>您提供的图片中第 3 题考查的是如何通过指针来配合 <code>scanf</code> 函数给变量 <code>i</code> 赋值。</p><p><strong>题目：</strong> 若定义了 <code>int i, *p;</code>，则能通过 <code>scanf</code> 函数给 <code>i</code> 输入读取数据的程序段是：</p><h3 id="scanf-的核心原则"><a href="#scanf-的核心原则" class="headerlink" title="scanf 的核心原则"></a><code>scanf</code> 的核心原则</h3><p><code>scanf</code> 是一个典型的<strong>传地址调用</strong>函数：它需要一个<strong>地址</strong>，以便将输入的数据写入该地址所在的内存。</p><h3 id="正确的赋值步骤"><a href="#正确的赋值步骤" class="headerlink" title="正确的赋值步骤"></a>正确的赋值步骤</h3><p>要通过指针 <code>p</code> 间接地给变量 <code>i</code> 赋值，程序段必须完成两件事：</p><ol><li><strong>建立连接：</strong> 指针 <code>p</code> 必须存储 <code>i</code> 的地址。</li><li><strong>传递地址：</strong> 将 <code>i</code> 的地址（即指针 <code>p</code> 的值）传递给 <code>scanf</code>。</li></ol><table><thead><tr><th><strong>步骤</strong></th><th><strong>代码</strong></th><th><strong>解释</strong></th></tr></thead><tbody><tr><td><strong>1. 建立连接</strong></td><td><code>p = &amp;i;</code></td><td>将 <code>i</code> 的地址赋给指针 <code>p</code>。</td></tr><tr><td><strong>2. 输入赋值</strong></td><td><code>scanf(&quot;%d&quot;, p);</code></td><td>传递 <code>p</code> 的值（即 <code>i</code> 的地址）给 <code>scanf</code>，<code>scanf</code> 将输入数据写入 <code>i</code> 所在的内存。</td></tr></tbody></table><h3 id=""><a href="#" class="headerlink" title=""></a></h3><h2 id="memory"><a href="#memory" class="headerlink" title="memory"></a>memory</h2><table><thead><tr><th><strong>内存区域</strong></th><th><strong>读写权限</strong></th><th><strong>生命周期</strong></th><th><strong>存储内容示例</strong></th></tr></thead><tbody><tr><td><strong>代码区 (.text)</strong></td><td>只读</td><td>整个程序生命周期</td><td>程序的机器指令（函数代码）</td></tr><tr><td><strong>只读数据区 (.rodata)</strong></td><td><strong>只读</strong></td><td>整个程序生命周期</td><td>字符串字面量、全局常量</td></tr><tr><td><strong>数据区 (.data)</strong></td><td>读写</td><td>整个程序生命周期</td><td>已初始化的全局变量和静态变量</td></tr><tr><td><strong>堆 (Heap)</strong></td><td>读写</td><td>动态分配和释放 (<code>malloc</code>&#x2F;<code>free</code>)</td><td>动态分配的内存块</td></tr><tr><td><strong>栈 (Stack)</strong></td><td>读写</td><td>函数调用周期</td><td>局部变量、函数参数、返回地址</td></tr></tbody></table><h1 id="Data-Structure"><a href="#Data-Structure" class="headerlink" title="Data Structure"></a>Data Structure</h1><p><img src="C:\Users\31575\AppData\Roaming\Typora\typora-user-images\image-20251202131055522.png" alt="image-20251202131055522"></p><p>您的理解已经抓住了数据结构的核心。现在，让我们深入到<strong>内存管理</strong>层面，详细解释数据结构是如何影响数据在计算机内存中的“摆放”和“管理”的。</p><hr><h2 id="A-数据结构与内存管理"><a href="#A-数据结构与内存管理" class="headerlink" title="A.数据结构与内存管理"></a>A.数据结构与内存管理</h2><p>数据结构在内存管理上主要关注<strong>两种核心的内存分配方式</strong>和由此产生的<strong>逻辑组织</strong>。</p><h3 id="一、-内存分配方式（物理存储）"><a href="#一、-内存分配方式（物理存储）" class="headerlink" title="一、 内存分配方式（物理存储）"></a>一、 内存分配方式（物理存储）</h3><p>计算机内存（RAM）可以看作是一个巨大的、连续的地址空间。数据结构决定了它们请求和使用这片空间的具体方式。</p><h4 id="1-连续存储-Contiguous-Allocation"><a href="#1-连续存储-Contiguous-Allocation" class="headerlink" title="1. 连续存储 (Contiguous Allocation)"></a>1. 连续存储 (Contiguous Allocation)</h4><ul><li><strong>代表结构：</strong> <strong>数组 (Array)</strong></li><li><strong>内存特性：</strong> 元素在内存中是<strong>紧挨着、连续存放</strong>的。</li><li><strong>管理方式：</strong><ul><li><strong>优点：</strong> 知道起始地址和元素大小，可以<strong>直接计算</strong>出任何一个元素的位置（地址 &#x3D; 起始地址 + 索引 $\times$ 元素大小）。这使得随机访问（如获取 $A[5]$）的速度非常快（$O(1)$ 时间复杂度）。</li><li><strong>缺点：</strong> 必须在创建时就预留<strong>一大块连续</strong>的空间。如果内存碎片化严重，即使总空间足够，也可能找不到足够大的连续空间来创建数组。<strong>插入&#x2F;删除</strong>操作非常慢，因为需要移动大量后续元素来保持连续性。</li></ul></li></ul><h4 id="2-离散存储-Non-Contiguous-Allocation"><a href="#2-离散存储-Non-Contiguous-Allocation" class="headerlink" title="2. 离散存储 (Non-Contiguous Allocation)"></a>2. 离散存储 (Non-Contiguous Allocation)</h4><ul><li><strong>代表结构：</strong> <strong>链表 (Linked List)</strong></li><li><strong>内存特性：</strong> 元素（节点）可以<strong>分散</strong>在内存的任何地方。</li><li><strong>管理方式：</strong><ul><li><strong>如何连接：</strong> 每个节点不仅存储数据，还存储一个**指针（Pointer）**或**引用（Reference）**，指向下一个节点的内存地址。</li><li><strong>优点：</strong> 插入和删除操作非常高效（$O(1)$），只需要修改少数几个指针，不需要移动数据。内存利用率高，因为它不需要大块连续空间。</li><li><strong>缺点：</strong> 访问元素时不能直接计算地址，必须从头节点开始，沿着指针一个个查找，访问速度较慢（$O(N)$）。</li></ul></li></ul><h3 id="二、-数据结构的逻辑组织（抽象管理）"><a href="#二、-数据结构的逻辑组织（抽象管理）" class="headerlink" title="二、 数据结构的逻辑组织（抽象管理）"></a>二、 数据结构的逻辑组织（抽象管理）</h3><p>除了底层的物理存储，数据结构还定义了数据的抽象<strong>访问规则</strong>，这才是栈、队列等概念的来源。</p><h4 id="1-栈-Stack-LIFO-规则"><a href="#1-栈-Stack-LIFO-规则" class="headerlink" title="1. 栈 (Stack) - LIFO 规则"></a>1. 栈 (Stack) - LIFO 规则</h4><ul><li><strong>逻辑管理：</strong> 强制只在<strong>一端</strong>（顶部，Top）进行数据的添加和移除。</li><li><strong>内存实现：</strong> 通常可以使用<strong>数组</strong>或<strong>链表</strong>实现。<ul><li><strong>数组实现：</strong> 用一个索引变量来指示 Top 的位置。</li><li><strong>应用：</strong> <strong>函数调用栈</strong>就是操作系统在内存中开辟的一个特定区域，用来管理函数执行流程。</li></ul></li></ul><h4 id="2-哈希表-Hash-Table-键值映射"><a href="#2-哈希表-Hash-Table-键值映射" class="headerlink" title="2. 哈希表 (Hash Table) - 键值映射"></a>2. 哈希表 (Hash Table) - 键值映射</h4><ul><li><strong>逻辑管理：</strong> 实现<strong>键（Key）</strong> 到 <strong>值（Value）</strong> 的快速映射。</li><li><strong>内存实现：</strong> 结合了<strong>数组</strong>和<strong>哈希函数</strong>。<ul><li><strong>哈希函数：</strong> 将任意大小的 Key 转化为数组的<strong>一个有效索引</strong>（地址）。</li><li><strong>冲突处理：</strong> 当多个 Key 映射到同一个索引时（<strong>哈希冲突</strong>），通常使用<strong>链表</strong>将这些冲突的元素连接起来（称为<strong>拉链法</strong>）。</li><li><strong>目的：</strong> 追求近乎 $O(1)$ 的平均查找速度。</li></ul></li></ul><h4 id="3-树-Tree-和-图-Graph-复杂关系管理"><a href="#3-树-Tree-和-图-Graph-复杂关系管理" class="headerlink" title="3. 树 (Tree) 和 图 (Graph) - 复杂关系管理"></a>3. 树 (Tree) 和 图 (Graph) - 复杂关系管理</h4><ul><li><strong>逻辑管理：</strong> 组织具有<strong>层级</strong>或<strong>网络</strong>关系的数据。</li><li><strong>内存实现：</strong> 通常使用<strong>离散存储</strong>（节点和指针）或<strong>邻接矩阵&#x2F;邻接表</strong>来实现。<ul><li><strong>邻接矩阵（数组实现）：</strong> 用一个二维数组 $M[i][j]$ 的值来表示节点 $i$ 和节点 $j$ 之间是否有连接。适用于稠密图（边多）。</li><li><strong>邻接表（链表实现）：</strong> 使用一个数组，数组的每个元素是一个链表，链表中存储了所有与该节点直接相连的节点。适用于稀疏图（边少）。</li></ul></li></ul><p>数据结构不仅是关于“把数据怎么放”的，它更是一个<strong>蓝图</strong>，定义了：</p><ol><li><strong>物理层面：</strong> 它们是连续存放还是离散存放的。</li><li><strong>逻辑层面：</strong> 它们之间的抽象关系（父子关系、前后关系、映射关系）。</li><li><strong>操作层面：</strong> 保证在特定操作（查找、插入、删除）上达到最高的效率。</li></ol><p>“抽象访问规则”正是将一种原始的存储方式（如数组或链表）转化为具有特定用途的<strong>抽象数据类型 (Abstract Data Type, ADT)</strong> 的关键。</p><p>让我详细解释一下这个概念，以及它是如何催生出栈、队列、字典这些我们熟悉的结构的。</p><hr><h2 id="B-抽象访问规则：从“物理”到“逻辑”"><a href="#B-抽象访问规则：从“物理”到“逻辑”" class="headerlink" title="B.抽象访问规则：从“物理”到“逻辑”"></a>B.抽象访问规则：从“物理”到“逻辑”</h2><h3 id="核心：物理实现-vs-抽象模型"><a href="#核心：物理实现-vs-抽象模型" class="headerlink" title="核心：物理实现 vs. 抽象模型"></a>核心：物理实现 vs. 抽象模型</h3><table><thead><tr><th><strong>维度</strong></th><th><strong>物理存储 (Physical Implementation)</strong></th><th><strong>抽象访问规则 (Abstract Model)</strong></th></tr></thead><tbody><tr><td><strong>关注点</strong></td><td><strong>如何实现</strong>：数据在内存中是连续的还是分散的。</td><td><strong>如何使用</strong>：用户可以对数据进行哪些操作，以及这些操作遵循什么限制。</td></tr><tr><td><strong>底层工具</strong></td><td>数组、链表、指针。</td><td>抽象的指令（如 <code>Push</code>、<code>Pop</code>、<code>Enqueue</code>）。</td></tr><tr><td><strong>概念层面</strong></td><td>机器级别，具体的内存地址。</td><td>用户级别，概念化、理想化的操作模型。</td></tr><tr><td><strong>举例</strong></td><td>内存地址 <code>0x1001</code> 到 <code>0x100A</code> 连续存放了 10 个整数。</td><td><strong>栈</strong>：只能从顶部存取数据；<strong>队列</strong>：从头部取，从尾部存。</td></tr></tbody></table><h3 id="抽象访问规则的本质"><a href="#抽象访问规则的本质" class="headerlink" title="抽象访问规则的本质"></a>抽象访问规则的本质</h3><p>“抽象访问规则”就是一套<strong>对底层存储的限制和约束</strong>。它不是定义数据<strong>怎么放</strong>（那是物理存储的任务），而是定义数据<strong>怎么用</strong>。</p><p>这种抽象的目的是：<strong>将用户从复杂的内存管理细节中解放出来，专注于数据结构带来的逻辑功能。</strong></p><h2 id="C-数据结构与算法"><a href="#C-数据结构与算法" class="headerlink" title="C.数据结构与算法"></a>C.数据结构与算法</h2><h2 id="1-数据结构-Data-Structure-：组织和存放"><a href="#1-数据结构-Data-Structure-：组织和存放" class="headerlink" title="1. 数据结构 (Data Structure)：组织和存放"></a>1. 数据结构 (Data Structure)：组织和存放</h2><p>数据结构本质上关注的是<strong>数据如何被组织和存储</strong>。您可以把它想象成一个仓库的<strong>设计图</strong>。</p><h3 id="核心关注点："><a href="#核心关注点：" class="headerlink" title="核心关注点："></a>核心关注点：</h3><ol><li><strong>数据的逻辑关系：</strong> 元素之间抽象的、概念上的关系（比如 LIFO、层级、网络连接）。</li><li><strong>数据的物理存储：</strong> 元素在计算机内存中是<strong>连续存放</strong>（如数组），还是<strong>分散存放并通过指针连接</strong>（如链表）。</li><li><strong>效率权衡：</strong> 如何摆放数据才能让特定的操作（如查找、插入）最快。</li></ol><h3 id="常见例子："><a href="#常见例子：" class="headerlink" title="常见例子："></a>常见例子：</h3><ul><li><strong>栈 (Stack):</strong> 遵守<strong>后进先出 (LIFO)</strong> 规则。</li><li><strong>队列 (Queue):</strong> 遵守<strong>先进先出 (FIFO)</strong> 规则。</li><li><strong>哈希表 (Hash Table):</strong> 为了实现快速键值映射。</li><li><strong>树 (Tree):</strong> 用于组织层次化数据，便于高效搜索。</li></ul><p><strong>总结：</strong> <strong>数据结构</strong>是<strong>名词</strong>，是存放数据的<strong>容器和组织形式</strong>。</p><hr><h2 id="2-算法-Algorithm-：解决问题的步骤"><a href="#2-算法-Algorithm-：解决问题的步骤" class="headerlink" title="2. 算法 (Algorithm)：解决问题的步骤"></a>2. 算法 (Algorithm)：解决问题的步骤</h2><p>算法本质上关注的是<strong>如何操作数据</strong>来解决一个特定的问题。您可以把它想象成仓库里完成任务的<strong>操作手册</strong>。</p><h3 id="核心关注点：-1"><a href="#核心关注点：-1" class="headerlink" title="核心关注点："></a>核心关注点：</h3><ol><li><strong>明确的步骤：</strong> 解决问题必须有一系列清晰、定义明确、有限的步骤。</li><li><strong>输入和输出：</strong> 接收有效的输入，并在有限时间内产生期望的输出。</li><li><strong>效率评估：</strong> 衡量完成任务所需的时间和资源（通常用<strong>时间复杂度</strong>和<strong>空间复杂度</strong>衡量）。</li></ol><h3 id="常见例子：-1"><a href="#常见例子：-1" class="headerlink" title="常见例子："></a>常见例子：</h3><ul><li><strong>排序算法:</strong> 如何将一组数据按升序或降序排列（如快速排序、归并排序）。</li><li><strong>搜索算法:</strong> 如何在一组数据中找到特定的元素（如二分查找）。</li><li><strong>图算法:</strong> 如何找到最短路径（如 Dijkstra 算法）。</li></ul><p><strong>总结：</strong> <strong>算法</strong>是<strong>动词</strong>，是处理数据的<strong>步骤和方法</strong>。</p><h1 id="Stack-and-Heap"><a href="#Stack-and-Heap" class="headerlink" title="Stack and Heap"></a>Stack and Heap</h1><h2 id="A-抽象访问规则"><a href="#A-抽象访问规则" class="headerlink" title="A.抽象访问规则"></a>A.抽象访问规则</h2><p>栈和队列是最能体现“抽象访问规则”的例子，它们都基于线性结构（比如链表或数组）实现，但通过不同的规则定义了完全不同的行为和应用场景。</p><h3 id="1-栈-Stack-：LIFO-规则的体现"><a href="#1-栈-Stack-：LIFO-规则的体现" class="headerlink" title="1. 栈 (Stack)：LIFO 规则的体现"></a>1. 栈 (Stack)：LIFO 规则的体现</h3><ul><li><strong>物理实现：</strong> 可以用一个链表来实现。</li><li><strong>抽象访问规则（LIFO 约束）：</strong><ul><li><strong>限制操作：</strong> 用户只能调用 <code>Push</code>（入栈）和 <code>Pop</code>（出栈）两个操作。</li><li><strong>LIFO 约束：</strong> <code>Push</code> 必须作用于链表的头部（或数组的末端）。<code>Pop</code> 也必须作用于同一位置。</li></ul></li><li><strong>总结：</strong> 栈将底层的链表或数组<strong>抽象化</strong>成了一个“只能一端进出”的容器。用户不需要关心它是数组还是链表，只需要知道它是一个 LIFO 结构。</li></ul><h3 id="2-队列-Queue-：FIFO-规则的体现"><a href="#2-队列-Queue-：FIFO-规则的体现" class="headerlink" title="2. 队列 (Queue)：FIFO 规则的体现"></a>2. 队列 (Queue)：FIFO 规则的体现</h3><ul><li><strong>物理实现：</strong> 也可以用一个链表来实现。</li><li><strong>抽象访问规则（FIFO 约束）：</strong><ul><li><strong>限制操作：</strong> 用户只能调用 <code>Enqueue</code>（入队）和 <code>Dequeue</code>（出队）。</li><li><strong>FIFO 约束：</strong> <code>Enqueue</code> 必须在<strong>队尾</strong>添加元素。<code>Dequeue</code> 必须从<strong>队头</strong>移除元素。</li></ul></li><li><strong>总结：</strong> 队列将底层的链表或数组<strong>抽象化</strong>成了一个“两端进出”的管道。这种抽象模型完美地模拟了现实世界中的排队行为。</li></ul><hr><h2 id="其他结构的抽象和用途"><a href="#其他结构的抽象和用途" class="headerlink" title="其他结构的抽象和用途"></a>其他结构的抽象和用途</h2><p>这种“定义抽象访问规则”的思维方式适用于所有高级数据结构：</p><table><thead><tr><th><strong>数据结构</strong></th><th><strong>底层物理实现（示例）</strong></th><th><strong>抽象访问规则&#x2F;约束</strong></th><th><strong>提供的核心功能</strong></th></tr></thead><tbody><tr><td><strong>哈希表</strong> (Hash Table)</td><td>数组 + 链表</td><td>必须通过**键（Key）**访问数据；Key 必须经过**哈希函数**转换成索引。</td><td>极速的 $O(1)$ 查找和插入。</td></tr><tr><td><strong>树</strong> (Tree)</td><td>节点 + 指针（链式结构）</td><td>每个节点最多有一个父节点；必须遵循特定的遍历顺序（如中序、前序、后序）。</td><td>高效的层次化组织和搜索（如二叉搜索树）。</td></tr><tr><td><strong>图</strong> (Graph)</td><td>节点 + 指针&#x2F;矩阵</td><td>允许节点之间建立<strong>任意</strong>连接（边）；必须通过特定的搜索算法（DFS&#x2F;BFS）来访问。</td><td>建模复杂的网络关系（如社交关系、地图路径）。</td></tr></tbody></table><p>正是这些“抽象访问规则”（即对底层操作的约束），使得<strong>数据结构</strong>从单纯的内存分配技巧（数组、链表）提升为强大的<strong>抽象数据类型</strong>（栈、队列、字典）。</p><p>它们规定了“数据的玩法”，而这种玩法是程序员解决特定问题的强大工具。您在使用 <code>Stack</code> 时，不需要知道它内部是用什么实现的，您只需要知道它遵守 LIFO 规则，这便是抽象的力量。</p><h2 id="B-具体实体"><a href="#B-具体实体" class="headerlink" title="B.具体实体"></a>B.具体实体</h2><p>它们具体的实体是什么，取决于您在编写代码时选择了哪种<strong>物理实现</strong>：</p><h3 id="实体形式一：基于-数组-的实现"><a href="#实体形式一：基于-数组-的实现" class="headerlink" title="实体形式一：基于 数组 的实现"></a>实体形式一：基于 <strong>数组</strong> 的实现</h3><p>如果您用数组（Array）来构建栈或队列：</p><ul><li><strong>具体实体：</strong> 栈&#x2F;队列就是内存中<strong>一块连续的、编号整齐的空间</strong>。</li><li><strong>具体管理：</strong><ul><li>程序会设置一个或两个<strong>整数变量</strong>（比如 <code>top</code> 或 <code>head</code> 和 <code>tail</code>），这些变量作为<strong>指针</strong>，告诉程序数据应该放在哪里、从哪里取出。</li><li>数据本身（比如数字、字符、对象）就一个个紧密地排列在这块内存空间里。</li></ul></li></ul><h3 id="实体形式二：基于-链表-的实现"><a href="#实体形式二：基于-链表-的实现" class="headerlink" title="实体形式二：基于 链表 的实现"></a>实体形式二：基于 <strong>链表</strong> 的实现</h3><p>如果您用链表（Linked List）来构建栈或队列：</p><ul><li><strong>具体实体：</strong> 栈&#x2F;队列是由多个**散落在内存各处的小盒子（节点）**组成的。</li><li><strong>具体管理：</strong><ul><li>每个<strong>小盒子</strong>包含两部分：您的<strong>数据</strong>和下一个小盒子的<strong>地址</strong>（即指针）。</li><li>程序会设置一个或两个<strong>指针变量</strong>（比如 <code>头指针</code> 和 <code>尾指针</code>），它们存储着第一个和&#x2F;或最后一个小盒子的内存地址。</li><li>这些小盒子<strong>不需要</strong>在内存中连续，它们通过互相指引的地址连接起来。</li></ul></li></ul><hr><h2 id="总结：抽象和具体的结合"><a href="#总结：抽象和具体的结合" class="headerlink" title="总结：抽象和具体的结合"></a>总结：抽象和具体的结合</h2><p>所以，栈和队列是<strong>具体的实体</strong>，它们是：</p><ol><li><strong>物理层面：</strong> 一串连续的字节（如果是数组实现），或者一系列由指针连接的节点（如果是链表实现），这些都是存在于**计算机内存（RAM）**中的真实数据。</li><li><strong>抽象层面：</strong> 在这些物理实体之上，<strong>编程语言的代码</strong>又强制性地赋予了它们 <strong>LIFO (栈)</strong> 或 <strong>FIFO (队列)</strong> 的访问规则。</li></ol><p><strong>它们既是“抽象概念”，又是“具体实体”，这种双重身份正是数据结构的精髓所在。</strong></p><ul><li><strong>抽象概念</strong>（LIFO&#x2F;FIFO）：告诉您<strong>怎么使用</strong>它们。</li><li><strong>具体实体</strong>（内存中的数组&#x2F;链表）：告诉您它们<strong>是怎么造出来的</strong>。</li></ul><p>对于一个程序员来说，当他说“我创建了一个栈”时，他的意思是：他<strong>在内存中分配了空间</strong>，并且<strong>写下了保证 LIFO 规则的代码</strong>。</p><h2 id="C-基于数组和链表实现的区别"><a href="#C-基于数组和链表实现的区别" class="headerlink" title="C.基于数组和链表实现的区别"></a>C.基于数组和链表实现的区别</h2><p>栈（Stack）和队列（Queue）都可以基于<strong>数组</strong>和<strong>链表</strong>这两种底层物理存储方式来实现。它们的主要区别在于**性能（时间复杂度）**和**空间效率**上的权衡。</p><h3 id="栈-Stack-的实现对比：数组-vs-链表"><a href="#栈-Stack-的实现对比：数组-vs-链表" class="headerlink" title="栈 (Stack) 的实现对比：数组 vs. 链表"></a>栈 (Stack) 的实现对比：数组 vs. 链表</h3><p>栈的操作集中在<strong>顶部（Top）</strong>，对应数组的末端或链表的头部。</p><table><thead><tr><th><strong>特性</strong></th><th><strong>基于数组的栈 (Array-based Stack)</strong></th><th><strong>基于链表的栈 (Linked List-based Stack)</strong></th></tr></thead><tbody><tr><td><strong>物理存储</strong></td><td>连续的内存块。</td><td>离散的内存块，通过指针连接。</td></tr><tr><td><strong>Push&#x2F;Pop 效率</strong></td><td><strong>$O(1)$</strong></td><td><strong>$O(1)$</strong></td></tr><tr><td><strong>空间效率</strong></td><td><strong>高</strong>：没有额外的指针开销。</td><td><strong>低</strong>：每个元素都需要额外的空间存储<strong>一个指针</strong>。</td></tr><tr><td><strong>内存开销</strong></td><td>存在<strong>空间浪费</strong>（预先分配过多）或<strong>空间不足</strong>（需要动态扩容）的风险。</td><td><strong>没有浪费</strong>：内存按需分配，但分配和释放内存有时间开销。</td></tr><tr><td><strong>动态性</strong></td><td>当数组满时，必须进行<strong>扩容操作</strong>（通常是复制到一个更大的数组），扩容成本高昂（$O(N)$）。</td><td><strong>天然动态</strong>：只要内存允许，可以无限增长，不需要扩容操作。</td></tr></tbody></table><p><strong>总结：</strong></p><ul><li><strong>数组栈：</strong> 适用于<strong>元素数量已知或变化不大</strong>的场景。它的读写速度快，但需要处理扩容问题。</li><li><strong>链表栈：</strong> 适用于<strong>元素数量变化巨大</strong>的场景。它灵活且能按需使用内存，但牺牲了额外的空间来存储指针。</li></ul><h3 id="队列-Queue-的实现对比：数组-vs-链表"><a href="#队列-Queue-的实现对比：数组-vs-链表" class="headerlink" title="队列 (Queue) 的实现对比：数组 vs. 链表"></a>队列 (Queue) 的实现对比：数组 vs. 链表</h3><p>队列的操作涉及**队头（Dequeue）<strong>和</strong>队尾（Enqueue）**两端。</p><table><thead><tr><th><strong>特性</strong></th><th><strong>基于数组的队列 (Array-based Queue)</strong></th><th><strong>基于链表的队列 (Linked List-based Queue)</strong></th></tr></thead><tbody><tr><td><strong>物理存储</strong></td><td>连续的内存块。</td><td>离散的内存块，通过指针连接。</td></tr><tr><td><strong>Enqueue (入队)</strong></td><td><strong>$O(1)$</strong> (在数组末尾)</td><td><strong>$O(1)$</strong> (如果维护了尾指针)</td></tr><tr><td><strong>Dequeue (出队)</strong></td><td><strong>$O(1)$</strong> (如果使用<strong>循环数组</strong>实现)；否则为 <strong>$O(N)$</strong> (如果每次出队后都要移动所有元素填补空位)。</td><td><strong>$O(1)$</strong> (在链表头部)</td></tr><tr><td><strong>空间效率</strong></td><td>同样存在扩容风险和空间浪费问题。<strong>循环数组</strong>可以解决浪费，但逻辑更复杂。</td><td><strong>低</strong>：每个元素都需要额外的空间存储<strong>一个指针</strong>。</td></tr><tr><td><strong>实现难度</strong></td><td><strong>高</strong>：实现高效的**循环队列（Circular Queue）**以避免 $O(N)$ 的移动开销和内存浪费，逻辑相对复杂。</td><td><strong>低</strong>：实现简单，只需要维护<strong>头指针</strong>和<strong>尾指针</strong>即可。</td></tr></tbody></table><p><strong>总结：</strong></p><ul><li><strong>数组队列：</strong> 只有通过<strong>循环数组</strong>的精巧设计，才能保证 Dequeue 操作也是 $O(1)$。这种实现最快，但代码难度较高。</li><li><strong>链表队列：</strong> <strong>实现最简单，性能最稳定</strong>，所有核心操作都是 $O(1)$，是实际开发中最常用的队列实现方式。</li></ul><h3 id="最终结论：实际选择倾向"><a href="#最终结论：实际选择倾向" class="headerlink" title="最终结论：实际选择倾向"></a>最终结论：实际选择倾向</h3><table><thead><tr><th><strong>数据结构</strong></th><th><strong>最佳选择及原因</strong></th></tr></thead><tbody><tr><td><strong>栈 (Stack)</strong></td><td>通常选择<strong>基于数组</strong>的实现。因为栈的操作都在一端，数组的连续存储提供了更高的空间效率和缓存优势。</td></tr><tr><td><strong>队列 (Queue)</strong></td><td>通常选择<strong>基于链表</strong>的实现。因为它自然地支持在两端（头和尾）进行 $O(1)$ 操作，避免了数组实现中复杂的循环队列逻辑和内存移动问题。</td></tr></tbody></table>]]></content>
    
    
    <categories>
      
      <category>study</category>
      
      <category>computer</category>
      
      <category>the c language</category>
      
    </categories>
    
    
  </entry>
  
  
  
  <entry>
    <title>movies</title>
    <link href="/2025/12/01/movies/"/>
    <url>/2025/12/01/movies/</url>
    
    <content type="html"><![CDATA[<h1 id="Movies"><a href="#Movies" class="headerlink" title="Movies"></a>Movies</h1>]]></content>
    
    
    <categories>
      
      <category>life</category>
      
      <category>movies</category>
      
    </categories>
    
    
  </entry>
  
  
  
  <entry>
    <title>book</title>
    <link href="/2025/12/01/book/"/>
    <url>/2025/12/01/book/</url>
    
    <content type="html"><![CDATA[<h1 id="book"><a href="#book" class="headerlink" title="book"></a>book</h1><h2 id="literature"><a href="#literature" class="headerlink" title="literature"></a>literature</h2><h3 id="《刀锋》"><a href="#《刀锋》" class="headerlink" title="《刀锋》"></a>《刀锋》</h3><p>难以描述阅读时的震撼之感</p><p>在拉里身上看到了自己的些许影子，也曾一度追问过意义与价值，却又迷惘彷徨而归。拉里厉害许多，他走遍各地，如饥似渴的阅读，体验，探索……</p><p>那样直观而震撼的感受到人类浩如烟海的知识与文明，往前看，有那样长的历史，那样丰富庞杂的学科与知识，踮脚眺望，有那样多的国家，那样丰富的人们，那样广阔的天地人间……顿感自己的渺小与恍若须臾片刻的生命时间，自己的思想是那样简单与浅薄，也顿感时间的紧迫与稍纵即逝，去阅读，去看，去思考，去感受世界，找到自己的答案…</p><p>呵，生命啊，它苦涩如歌</p>]]></content>
    
    
    <categories>
      
      <category>life</category>
      
      <category>book</category>
      
    </categories>
    
    
  </entry>
  
  
  
  <entry>
    <title>linear algebra</title>
    <link href="/2025/12/01/linear%20algebra/"/>
    <url>/2025/12/01/linear%20algebra/</url>
    
    <content type="html"><![CDATA[<h1 id="linear-algebra"><a href="#linear-algebra" class="headerlink" title="linear algebra"></a>linear algebra</h1><h2 id="秩一矩阵"><a href="#秩一矩阵" class="headerlink" title="秩一矩阵"></a>秩一矩阵</h2><p>[TOC]</p><h2 id="正交矩阵"><a href="#正交矩阵" class="headerlink" title="正交矩阵"></a>正交矩阵</h2><h3 id="T1-when-Ax-b-have-no-solution"><a href="#T1-when-Ax-b-have-no-solution" class="headerlink" title="T1:when Ax&#x3D;b have no solution"></a>T1:when Ax&#x3D;b have no solution</h3><p>$$<br>A\mathbf{x}&#x3D;\mathbf{b}无解时，为什么求最佳\mathbf{x}_{best}转化为A^TA\mathbf{x}&#x3D;A^T\mathbf{b}<br>$$</p><p><img src="C:\Users\31575\AppData\Roaming\Typora\typora-user-images\image-20251122120955823.png" alt="image-20251122120955823"></p><p><img src="C:\Users\31575\AppData\Roaming\Typora\typora-user-images\image-20251122121007424.png" alt="image-20251122121007424"></p><p><img src="C:\Users\31575\AppData\Roaming\Typora\typora-user-images\image-20251122121032475.png" alt="image-20251122121032475"></p><p><img src="C:\Users\31575\AppData\Roaming\Typora\typora-user-images\image-20251122121047812.png" alt="image-20251122121047812"></p><p><img src="C:\Users\31575\AppData\Roaming\Typora\typora-user-images\image-20251122121100100.png" alt="image-20251122121100100"></p>]]></content>
    
    
    <categories>
      
      <category>study</category>
      
      <category>math</category>
      
      <category>linear algebra</category>
      
    </categories>
    
    
  </entry>
  
  
  
  
</search>
